# üå¨Ô∏è Airflow Data Engineering Pipeline Project

This repository contains a complete Data Engineering pipeline using **Apache Airflow**, designed to demonstrate scheduling, orchestration, data ingestion, transformation, and inter-task communication.



## üöÄ Project Overview üìò

### üìå Objective
Automate a data pipeline that:
- Loads and transforms FX and product data from **Amazon S3** to **Snowflake**
- Handles scheduling, conditional branching, task retries, and dataset dependencies
- Demonstrates Airflow features like **XComs**, **Trigger Rules**, **Hooks**, and **Custom Operators**



## üß∞ Tools & Technologies Used

| Tool / Tech        | Purpose                                           |
|--------------------|---------------------------------------------------|
| **Apache Airflow** | Workflow orchestration and scheduling             |
| **Snowflake**      | Cloud data warehouse (final data store)           |
| **Amazon S3**      | Raw data storage (landing zone)                   |
| **Python**         | Data processing logic, Airflow DAGs               |
| **Docker**         | Containerized Airflow environment                 |
| **SQL**            | Data transformations in Snowflake                 |
| **VS Code**        | IDE for development                               |



## üèóÔ∏è Project Structure

```
airflow/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ conditional_branching.py
‚îÇ   ‚îú‚îÄ‚îÄ data_process.py
‚îÇ   ‚îú‚îÄ‚îÄ fx_data_consumer.py
‚îÇ   ‚îú‚îÄ‚îÄ hybrid_dec.py
‚îÇ   ‚îú‚îÄ‚îÄ latest_only.py
‚îÇ   ‚îú‚îÄ‚îÄ taskflow_dec.py
‚îÇ   ‚îú‚îÄ‚îÄ trigger_rule.py
‚îÇ   ‚îî‚îÄ‚îÄ xrate_to_s3.py
‚îú‚îÄ‚îÄ plugins/
‚îÇ   ‚îú‚îÄ‚îÄ email_operator.py
‚îÇ   ‚îî‚îÄ‚îÄ email_trigger.py
‚îú‚îÄ‚îÄ sqls/
‚îÇ   ‚îú‚îÄ‚îÄ profit_uk.sql
‚îÇ   ‚îú‚îÄ‚îÄ xrate_sf.sql
‚îÇ   ‚îî‚îÄ‚îÄ live_exchange_rate.sql
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ .env

```
## üìå Architecture
![Pipeline Architecture](datasets/etl_architect.jpg)


## üîÑ Key Concepts Demonstrated

- **TaskFlow API** and **traditional DAG styles**
- `@task` decorator for cleaner Python logic
- **Trigger Rules**: `all_success`, `one_failed`, `all_done`, etc.
- **XComs**: Passing data between tasks
- **Branching** with `BranchPythonOperator`
- **Hooks**: Custom and built-in integrations
- **Custom Operators** in the `plugins/` folder
- **LatestOnlyOperator**: Prevents historical backfill
- Loading into Snowflake with `external_stage` and `LATERAL FLATTEN`

---

## üß™ Example Workflow

1. Data is ingested from S3 (CSV/JSON)
2. Scheduled DAGs manage data ingestion and transformation
3. Branching logic based on file type or conditions
4. Data is transformed and loaded into Snowflake
5. Email notification sent via custom operator

## üìå Eamails Notifications from DAGs
![email_notifications](datasets/dag_notifications_in_mail.jpg)

---


## üê≥ Run Locally with Docker

### üß± Prerequisites:
- Docker + Docker Compose installed
- Access Airflow UI: [http://localhost:8080](http://localhost:8080)
- Default login: `airflow / airflow`

---

## üì¨ Outputs

- Transformed data in Snowflake
- Logs and audit trails in Airflow
- Intermediate files handled via `/tmp` and S3

---

## üîó Summary

> üöÄ Built a complete data pipeline using Apache Airflow with S3, Snowflake, and Python.  
> üß© Integrated XComs, Branching, Trigger Rules, Hooks, and Custom Operators.  
> üê≥ Containerized with Docker for reproducible workflows.  
> üìä Loaded and transformed FX and product data into Snowflake using modern ETL architecture.  
> üéØ Emphasized reliability, modularity, and clean orchestration logic.

---

## üôå Acknowledgments

- Inspired by modern medallion architecture practices
- Referenced official docs: [Apache Airflow Documentation](https://airflow.apache.org/docs/)

- ## üõ°Ô∏è License

This project is licensed under the [MIT License](LICENSE). You are free to use, modify, and share this project with proper attribution.


[![dev.to](https://img.shields.io/badge/Dev.to-0A0A0A?style=for-the-badge&logo=DevdotTo&logoColor=white)](https://dev.to/brian_otina_)
[![github](https://img.shields.io/badge/GitHub-000000?style=for-the-badge&logo=GitHub&logoColor=white)](https://github.com/otinabrayo)
[![gmail](https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=Gmail&logoColor=white)](mailto:brianotina20@gmail.com)
[![telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white)](https://t.me/just_otina)
[![discord](https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white)](https://discord.com/channels/@otina_)

```
